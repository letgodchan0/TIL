







# [컴퓨터 구조] - 데이터

컴퓨터가 이해하는 가장 작은 정보 비트(0과 1을 표현)

<hr>

<br>

|                   |                           |
| ----------------- | ------------------------- |
| 1 바이트(1byte)   | 8 비트(8bit)              |
| 1 킬로바이트(1KB) | 1,000 바이트(1,000byte)   |
| 1 메가바이트(1MB) | 1,000 킬로바이트(1,000KB) |
| 1 기가바이트(1GB) | 1,000 메가바이트(1,000MB) |
| 1 테라바이트(1TB) | 1,000 기가바이트(1,000GB) |

<br>

컴퓨터는 0과 1을 표현하기 위해 이진수를 사용한다. 음수 같은 경우 2의 보수를 사용하기도 하지만, 실제 이진수만 봐서는 이게 음수인지 양수인지 구분하기 어렵다. 따라서 컴퓨터 내부에서는 양수인지 음수인지 구분하기 위해 "플래그"를 사용한다.

플래그란, 쉽게 말해 부호를 가지고 있는 것 정도로 생각하자.

<br>

#### - 0과 1로 문자 표현하기

1. 문자 집합 : 컴퓨터가 인식하고 표현할 수 있는 문자의 모음
2. 문자 인코딩: 한글, 알파벳과 같은 문자를 0과 1로 변환하는 과정, 같은 문자 집합에 대해서도 다양한 인코딩 방식 존재
3. 문자 디코딩: 인코딩의 반대 과정, 즉 0과 1로 이루어진 문자 코드를 사람이 이해할 수 있는 문자로 변환하는 과정

<br>

#### - 아스키 코드

초창기 문자 집합 중 하나로, 영어 알파벳과 아라비아 숫자, 그리고 일부 특수 문자를 포함한다. 아스키 문자 집합에 속한 문자들은 각각 7비트로 표현된다. 즉, 총 128개의 문자를 표현할 수 있다. 

<br>

#### - EUC-KR

KS X 1001, KS X 1003이라는 문자 집합을 기반으로 하는 대표적인 완성형 인코딩 방식으로 초성, 중성, 종성이 모두 결합된 한글 단어에 2바이트 크기의 코드를 부여한다. 

즉, 한글 한 글자를 표현하기 위해 16비트가 필요하다. 

<br>

#### - 유니코드

대부분 국가의 문자, 특수문자, 화살표, 이모티콘 등을 코드로 표현하는 통일된 문자집합. 

유니코드는 글자에 부여된 값 자체를 인코딩된 값으로 삼지 않고 이 값을 다양한 방법으로 인코딩한다. 크게 UTF-8, UTF-16 등이 존재한다.











